{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bepub V.1.0.0"
      ],
      "metadata": {
        "id": "XHWER1jNiyZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "gbDsjwMye8k0",
        "outputId": "22db3ce8-fb65-49d4-c84d-46bfe7898d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
        "!pip install -q typhoon-ocr ebooklib unicodedata2 pdfplumber PyPDF2 markdown\n",
        "!apt-get install -y poppler-utils > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import zipfile\n",
        "import markdown\n",
        "import shutil\n",
        "import gradio as gr\n",
        "from PyPDF2 import PdfReader, PdfWriter\n",
        "from typhoon_ocr import ocr_document\n",
        "\n",
        "is_cancelled = False\n",
        "\n",
        "def cancel_process():\n",
        "    global is_cancelled\n",
        "    is_cancelled = True\n",
        "    return \"üõë ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î...\"\n",
        "\n",
        "def process_and_build_epub(api_key, pdf_file, start_page, end_page, custom_remove, progress=gr.Progress()):\n",
        "    global is_cancelled\n",
        "    is_cancelled = False\n",
        "\n",
        "    if not api_key or not pdf_file:\n",
        "        return None, None, \"‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API Key ‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå PDF\"\n",
        "\n",
        "    s_p = int(start_page)\n",
        "    e_p = int(end_page)\n",
        "\n",
        "    input_path = pdf_file.name\n",
        "    full_raw_name = os.path.basename(input_path)\n",
        "    base_name = full_raw_name.rsplit('.', 1)[0]\n",
        "\n",
        "    recovery_txt = \"temp_recovery_content.txt\"\n",
        "    if os.path.exists(recovery_txt): os.remove(recovery_txt)\n",
        "\n",
        "    full_text_content = \"\"\n",
        "\n",
        "    try:\n",
        "        os.environ[\"TYPHOON_OCR_API_KEY\"] = api_key\n",
        "        reader = PdfReader(input_path)\n",
        "        total_in_pdf = len(reader.pages)\n",
        "        actual_end = total_in_pdf if (e_p == 0 or e_p > total_in_pdf) else e_p\n",
        "        target_indices = [i - 1 for i in range(s_p, actual_end + 1)]\n",
        "\n",
        "        for idx in progress.tqdm(target_indices, desc=\"‡∏Å‡∏≥‡∏•‡∏±‡∏á OCR\"):\n",
        "            if is_cancelled: break\n",
        "\n",
        "            p_num = idx + 1\n",
        "            temp_pdf = f\"temp_page_{p_num}.pdf\"\n",
        "            writer = PdfWriter()\n",
        "            writer.add_page(reader.pages[idx])\n",
        "            with open(temp_pdf, \"wb\") as f: writer.write(f)\n",
        "\n",
        "            try:\n",
        "                page_res = ocr_document(temp_pdf)\n",
        "                if page_res:\n",
        "                    # ‡πÉ‡∏ä‡πâ 'NFC' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡πÑ‡∏°‡πà‡πÅ‡∏¢‡∏Å‡∏ä‡∏±‡πâ‡∏ô\n",
        "                    text = unicodedata.normalize('NFC', str(page_res))\n",
        "                    full_text_content += text + \"\\n\\n--- Page Break ---\\n\\n\"\n",
        "                    with open(recovery_txt, \"a\", encoding=\"utf-8-sig\") as f:\n",
        "                        f.write(text + \"\\n\\n--- Page Break ---\\n\\n\")\n",
        "            finally:\n",
        "                if os.path.exists(temp_pdf): os.remove(temp_pdf)\n",
        "\n",
        "        status_final = \"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\" if not is_cancelled else \"üõë ‡∏´‡∏¢‡∏∏‡∏î‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\"\n",
        "\n",
        "        # ‡∏™‡πà‡∏á base_name ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
        "        txt_path, epub_path, _ = final_build(full_text_content, base_name)\n",
        "        return txt_path, epub_path, status_final\n",
        "\n",
        "    except Exception as e:\n",
        "        if full_text_content:\n",
        "            txt_path, epub_path, _ = final_build(full_text_content, f\"RECOVERED_{base_name}\")\n",
        "            return txt_path, epub_path, f\"‚ö†Ô∏è Error: {str(e)}\"\n",
        "        return None, None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def final_build(content, base_name):\n",
        "    if not content.strip(): return None, None, \"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤\"\n",
        "\n",
        "    # ‡∏Ñ‡∏•‡∏µ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "    clean = re.sub(r'\\n\\*\\s*\\d+\\s*\\n|\\*\\s*\\d+\\s*\\*|\\'', '', content)\n",
        "    clean = re.sub(r'\\n\\s*\\n', '\\n\\n', clean)\n",
        "    sections = clean.split('--- Page Break ---')\n",
        "\n",
        "    build_dir = \"epub_build_temp\"\n",
        "    if os.path.exists(build_dir): shutil.rmtree(build_dir)\n",
        "    os.makedirs(f'{build_dir}/OEBPS', exist_ok=True)\n",
        "    os.makedirs(f'{build_dir}/META-INF', exist_ok=True)\n",
        "\n",
        "    with open(f'{build_dir}/mimetype', 'w') as f: f.write('application/epub+zip')\n",
        "    with open(f'{build_dir}/META-INF/container.xml', 'w') as f:\n",
        "        f.write('<?xml version=\"1.0\"?><container version=\"1.0\" xmlns=\"urn:oasis:names:tc:opendocument:xmlns:container\"><rootfiles><rootfile full-path=\"OEBPS/content.opf\" media-type=\"application/oebps-package+xml\"/></rootfiles></container>')\n",
        "\n",
        "    manifest, spine = \"\", \"\"\n",
        "    for i, sec in enumerate(sections):\n",
        "        if not sec.strip(): continue\n",
        "        html = markdown.markdown(sec.strip())\n",
        "        f_name = f'p{i}.xhtml'\n",
        "        with open(f'{build_dir}/OEBPS/{f_name}', 'w', encoding='utf-8') as f:\n",
        "            f.write(f'<html><body>{html}</body></html>')\n",
        "        manifest += f'<item id=\"p{i}\" href=\"{f_name}\" media-type=\"application/xhtml+xml\"/>\\n'\n",
        "        spine += f'<itemref idref=\"p{i}\"/>\\n'\n",
        "\n",
        "    # ‡πÉ‡∏ô content.opf ‡πÉ‡∏ä‡πâ base_name ‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πá‡∏ô Title\n",
        "    with open(f'{build_dir}/OEBPS/content.opf', 'w', encoding='utf-8') as f:\n",
        "        f.write(f'<?xml version=\"1.0\"?><package xmlns=\"http://www.idpf.org/2007/opf\" version=\"2.0\"><metadata xmlns:dc=\"http://purl.org/dc/elements/1.1/\"><dc:title>{base_name}</dc:title><dc:language>th</dc:language></metadata><manifest>{manifest}<item id=\"ncx\" href=\"toc.ncx\" media-type=\"application/x-dtbncx+xml\"/></manifest><spine toc=\"ncx\">{spine}</spine></package>')\n",
        "\n",
        "    with open(f'{build_dir}/OEBPS/toc.ncx', 'w', encoding='utf-8') as f:\n",
        "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?><ncx xmlns=\"http://www.daisy.org/z3986/2005/ncx/\" version=\"2005-1\"><navMap><navPoint id=\"n1\" playOrder=\"1\"><navLabel><text>Start</text></navLabel><content src=\"p0.xhtml\"/></navPoint></navMap></ncx>')\n",
        "\n",
        "    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output\n",
        "    epub_name = unicodedata.normalize(\"NFC\", f\"{base_name}.epub\")\n",
        "    txt_name = unicodedata.normalize(\"NFC\", f\"{base_name}.txt\")\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå TXT\n",
        "    with open(txt_name, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "    # ‡πÅ‡∏û‡πá‡∏Ñ‡πÑ‡∏ü‡∏•‡πå ZIP\n",
        "    with zipfile.ZipFile(epub_name, 'w', zipfile.ZIP_DEFLATED) as z:\n",
        "        for r, d, fs in os.walk(build_dir):\n",
        "            for file in fs:\n",
        "                file_path = os.path.join(r, file)\n",
        "                z.write(file_path, os.path.relpath(file_path, build_dir))\n",
        "\n",
        "    shutil.rmtree(build_dir)\n",
        "    return txt_name, epub_name, \"‚úÖ\"\n",
        "\n",
        "# --- UI Interface ---\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            file_input = gr.File(label=\"üìÇ 1. Upload PDF\", file_types=[\".pdf\"])\n",
        "        with gr.Column(scale=1):\n",
        "            with gr.Group():\n",
        "                gr.Markdown(\"### ‚öôÔ∏è Configs\")\n",
        "                api_input = gr.Textbox(label=\"API Key\", type=\"password\")\n",
        "                with gr.Row():\n",
        "                    start_in = gr.Number(label=\"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏ô‡πâ‡∏≤\", value=1, precision=0)\n",
        "                    end_in = gr.Number(label=\"‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î\", value=1000, precision=0)\n",
        "                custom_remove = gr.Textbox(label=\"‡∏•‡∏ö‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡πÉ‡∏ä‡πâ , ‡∏Ñ‡∏±‡πà‡∏ô)\")\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_start = gr.Button(\"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\", variant=\"primary\", scale=1)\n",
        "        btn_stop = gr.Button(\"üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\", variant=\"stop\", scale=1)\n",
        "\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"### üì• Download Results\")\n",
        "        status_msg = gr.Textbox(label=\"Status\", interactive=False)\n",
        "        with gr.Row():\n",
        "            epub_output = gr.File(label=\"‡πÑ‡∏ü‡∏•‡πå EPUB\")\n",
        "            txt_output = gr.File(label=\"‡πÑ‡∏ü‡∏•‡πå TXT\")\n",
        "\n",
        "    # ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
        "    btn_start.click(\n",
        "        fn=process_and_build_epub,\n",
        "        inputs=[api_input, file_input, start_in, end_in, custom_remove],\n",
        "        outputs=[txt_output, epub_output, status_msg]\n",
        "    )\n",
        "\n",
        "    # ‡∏´‡∏≤‡∏Å‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î\n",
        "    btn_stop.click(fn=cancel_process, outputs=status_msg)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "-hoDTg2Ye-4S",
        "outputId": "4a0f8fa1-1c7f-48fc-9c21-e4fbe1e638bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://54b33f69779fb738b8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://54b33f69779fb738b8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lUs-STLfPs5p"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}